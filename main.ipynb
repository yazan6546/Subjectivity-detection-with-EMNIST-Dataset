{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vf6omna0i_tZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PKvGc21t5mG",
        "outputId": "f2aaf8dc-ab7c-48a5-bb66-5892c0eb3e75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "byRRFO16kvRF"
      },
      "outputs": [],
      "source": [
        "# Load the mapping from mapping.txt\n",
        "def load_mapping(mapping_file):\n",
        "    mapping = {}\n",
        "    with open(mapping_file, 'r') as f:\n",
        "        for line in f:\n",
        "            key, value = line.strip().split()\n",
        "            mapping[int(key)] = chr(int(value))\n",
        "    return mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPWYS748oK8S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "kSYZtm6rj1Vx",
        "outputId": "5896d782-b3bf-4d6c-a56a-2a835d43268c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Display the first few images along with their ASCII labels\n",
        "def show_images(dataset, mapping, num_images=5):\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
        "    for i in range(num_images):\n",
        "        image, label = dataset[i]\n",
        "        image = image.numpy().squeeze()\n",
        "        ascii_label = mapping[label]\n",
        "        axes[i].imshow(image, cmap='gray')\n",
        "        axes[i].set_title(f'Label: {ascii_label}')\n",
        "        axes[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "show_images(dataset, mapping=mapping, num_images=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7qo0opU1uMp"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efXx47iDy2PH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7j8cuJB-2n59"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "class CharacterDataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.labels = self.data.iloc[:, 0].values\n",
        "        self.images = self.data.iloc[:, 1:].values.reshape(-1, 28, 28).astype('float32')\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "Wk9IcGW38VLu",
        "outputId": "f5a253db-73a6-4e1b-f43f-2c3d06c5792f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'batch_size' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c4c2d792be20>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create DataLoader for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "PATH='drive/MyDrive/Subjectivity'\n",
        "\n",
        "test_csv_file = os.path.join(PATH, 'data', 'characters-test.csv')\n",
        "test_dataset = CharacterDataset(test_csv_file, transform=transform)\n",
        "\n",
        "# Create DataLoader for testing\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9kES4iX8Nt7",
        "outputId": "77bbd806-4b4b-411c-a783-09fdf4cca769"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 75.4029469652641%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# # Evaluate the model on the test dataset\n",
        "# model.eval()\n",
        "# correct = 0\n",
        "# total = 0\n",
        "# with torch.no_grad():\n",
        "#     for images, labels in test_dataloader:\n",
        "#         images, labels = images.to(device), labels.to(device)\n",
        "#         outputs = model(images)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "\n",
        "# print(f'Test Accuracy: {100 * correct / total}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw3dzbgdxWFI",
        "outputId": "e300581f-34bd-4446-f463-fa4158ad2d87"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ksCCAihC26gy"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "\n",
        "class CharacterDataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.labels = self.data.iloc[:, 0].values\n",
        "        self.images = self.data.iloc[:, 1:].values.reshape(-1, 28, 28).astype('float32')\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),  # Convert single-channel to three channels\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SGDEBozJHceJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PATH='drive/MyDrive/Subjectivity'\n",
        "\n",
        "# Load the dataset\n",
        "csv_file = os.path.join(PATH, 'data', 'characters.csv')\n",
        "train_dataset = CharacterDataset(csv_file, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yj8cbat-HXZ1"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_csv_file = os.path.join(PATH, 'data', 'characters-test.csv')\n",
        "\n",
        "test_dataset = CharacterDataset(test_csv_file, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OIFQpCgZxTJC"
      },
      "outputs": [],
      "source": [
        "mapping_file = os.path.join(PATH, 'data', 'mapping.txt')\n",
        "mapping = load_mapping(mapping_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8VQAGv9xGzRi"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to create the model\n",
        "def create_model():\n",
        "    model = models.resnet18(pretrained=True)\n",
        "\n",
        "    # Move the model to GPU if available\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    print(device)\n",
        "\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, len(mapping))\n",
        "\n",
        "    # Freeze all layers except the last three\n",
        "    for name, param in model.named_parameters():\n",
        "        if \"layer4\" not in name and \"fc\" not in name:\n",
        "            param.requires_grad = False\n",
        "\n",
        "    return model\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(model, train_dataloader, learning_rate, num_epochs=10):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_dataloader)}')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Function to save the model\n",
        "def save_model(model, learning_rate, batch_size):\n",
        "    model_path = f'resnet18_finetuned_lr{learning_rate}_bs{batch_size}.pth'\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f'Model saved to {model_path}')\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, test_dataloader):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Test Accuracy: {accuracy}%')\n",
        "    return accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ohJHUjNG-6R",
        "outputId": "9be8e242-6fbf-4979-bbad-43c73dcd3382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with learning rate: 0.0001, batch size: 32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 150MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Experiment with different learning rates and batch sizes\n",
        "learning_rates = [0.0001]\n",
        "batch_sizes = [32, 64]\n",
        "\n",
        "results = []\n",
        "for lr in learning_rates:\n",
        "    for bs in batch_sizes:\n",
        "        print(f'Training with learning rate: {lr}, batch size: {bs}')\n",
        "\n",
        "        # Create DataLoader for training\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
        "        test_dataloader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
        "\n",
        "        # Create and train the model\n",
        "        model = create_model()\n",
        "        model = train_model(model, train_dataloader, lr)\n",
        "\n",
        "        # Save the model\n",
        "        save_model(model, lr, bs)\n",
        "\n",
        "        # Evaluate the model\n",
        "        accuracy = evaluate_model(model, test_dataloader)\n",
        "        results.append((lr, bs, accuracy))\n",
        "\n",
        "# Print results\n",
        "for lr, bs, acc in results:\n",
        "    print(f'Learning Rate: {lr}, Batch Size: {bs}, Test Accuracy: {acc}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "\n",
        "class CharacterDataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.labels = self.data.iloc[:, 0].values\n",
        "        self.images = self.data.iloc[:, 1:].values.reshape(-1, 28, 28).astype('float32')\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Load the mapping from mapping.txt\n",
        "def load_mapping(mapping_file):\n",
        "    mapping = {}\n",
        "    with open(mapping_file, 'r') as f:\n",
        "        for line in f:\n",
        "            key, value = line.strip().split()\n",
        "            mapping[int(key)] = chr(int(value))\n",
        "    return mapping\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.Grayscale(num_output_channels=1),  # Ensure single-channel images\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load the training dataset\n",
        "csv_file = 'characters.csv'\n",
        "mapping_file = 'mapping.txt'\n",
        "mapping = load_mapping(mapping_file)\n",
        "train_dataset = CharacterDataset(csv_file, transform=transform)\n",
        "\n",
        "# Load the test dataset\n",
        "test_csv_file = 'characters_test.csv'\n",
        "test_dataset = CharacterDataset(test_csv_file, transform=transform)\n",
        "\n",
        "# Custom CNN class\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes, num_conv_layers=3, num_fc_layers=2, dropout_rate=0.5):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "        \n",
        "        # Add convolutional layers\n",
        "        in_channels = 1\n",
        "        out_channels = 32\n",
        "        for _ in range(num_conv_layers):\n",
        "            self.conv_layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1))\n",
        "            self.conv_layers.append(nn.ReLU())\n",
        "            self.conv_layers.append(nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n",
        "            in_channels = out_channels\n",
        "            out_channels *= 2\n",
        "        \n",
        "        # Calculate the size of the flattened feature map\n",
        "        self.flattened_size = in_channels * (28 // (2 ** num_conv_layers)) ** 2\n",
        "        \n",
        "        # Add fully connected layers\n",
        "        in_features = self.flattened_size\n",
        "        out_features = 256\n",
        "        for _ in range(num_fc_layers - 1):\n",
        "            self.fc_layers.append(nn.Linear(in_features, out_features))\n",
        "            self.fc_layers.append(nn.ReLU())\n",
        "            self.fc_layers.append(nn.Dropout(dropout_rate))\n",
        "            in_features = out_features\n",
        "        \n",
        "        # Add the final fully connected layer\n",
        "        self.fc_layers.append(nn.Linear(in_features, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.conv_layers:\n",
        "            x = layer(x)\n",
        "        x = x.view(-1, self.flattened_size)\n",
        "        for layer in self.fc_layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(model, train_dataloader, learning_rate, num_epochs=10):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_dataloader)}')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Function to save the model\n",
        "def save_model(model, learning_rate, batch_size, num_conv_layers, num_fc_layers):\n",
        "    model_path = f'custom_cnn_lr{learning_rate}_bs{batch_size}_conv{num_conv_layers}_fc{num_fc_layers}.pth'\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f'Model saved to {model_path}')\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, test_dataloader):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Test Accuracy: {accuracy}%')\n",
        "    return accuracy\n",
        "\n",
        "# Experiment with different hyperparameters\n",
        "learning_rates = [0.001]\n",
        "batch_sizes = [64]\n",
        "num_conv_layers_list = [2, 3]\n",
        "num_fc_layers_list = [1, 2]\n",
        "\n",
        "results = []\n",
        "for lr in learning_rates:\n",
        "    for bs in batch_sizes:\n",
        "        for num_conv_layers in num_conv_layers_list:\n",
        "            for num_fc_layers in num_fc_layers_list:\n",
        "                print(f'Training with learning rate: {lr}, batch size: {bs}, conv layers: {num_conv_layers}, fc layers: {num_fc_layers}')\n",
        "                \n",
        "                # Create DataLoader for training\n",
        "                train_dataloader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
        "                test_dataloader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
        "                \n",
        "                # Create and train the model\n",
        "                model = CustomCNN(num_classes=len(mapping), num_conv_layers=num_conv_layers, num_fc_layers=num_fc_layers)\n",
        "                model = train_model(model, train_dataloader, lr)\n",
        "                \n",
        "                # Save the model\n",
        "                save_model(model, lr, bs, num_conv_layers, num_fc_layers)\n",
        "                \n",
        "                # Evaluate the model\n",
        "                accuracy = evaluate_model(model, test_dataloader)\n",
        "                results.append((lr, bs, num_conv_layers, num_fc_layers, accuracy))\n",
        "\n",
        "# Print results\n",
        "for lr, bs, num_conv_layers, num_fc_layers, acc in results:\n",
        "    print(f'Learning Rate: {lr}, Batch Size: {bs}, Conv Layers: {num_conv_layers}, FC Layers: {num_fc_layers}, Test Accuracy: {acc}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
